{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import numpy as onp\n",
    "import jax.flatten_util\n",
    "import pandas as pd\n",
    "import optax\n",
    "import jaxopt\n",
    "from flax.training import train_state\n",
    "import scipy\n",
    "from neuralss import ss_init, ss_apply\n",
    "from ae import Encoder, Projector\n",
    "import nonlinear_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.key(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_default_device\", jax.devices(\"gpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path(\"out\") / f\"hypernet.p\"\n",
    "ckpt = pickle.load(open(ckpt_path, \"rb\"))\n",
    "\n",
    "cfg = ckpt[\"cfg\"]\n",
    "params_enc, params_proj, params_ss = ckpt[\"params\"]\n",
    "scalers = ckpt[\"scalers\"]\n",
    "params_dec_flat, unflatten_dec = jax.flatten_util.ravel_pytree(params_ss)\n",
    "n_params = params_dec_flat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lens = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1_000, 2000, 3000, 4000, 5000]\n",
    "mc_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"bwdataset\"\n",
    "data_folder = Path(data_folder)\n",
    "data = scipy.io.loadmat(data_folder / \"bw_matlab.mat\")\n",
    "\n",
    "y_train = data[\"y\"] / 7e-4\n",
    "u_train = data[\"u\"] / 50.0\n",
    "\n",
    "y_test = scipy.io.loadmat(data_folder / \"yval_multisine.mat\")[\"yval_multisine\"].reshape(-1, 1) / 7e-4\n",
    "u_test = scipy.io.loadmat(data_folder / \"uval_multisine.mat\")[\"uval_multisine\"].reshape(-1, 1) / 50.0\n",
    "N = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(mlp_layers=[cfg.nh, cfg.nz], rnn_size=cfg.nh)\n",
    "proj = Projector(outputs=n_params,  unflatten=unflatten_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_reduced(ov, y, u):\n",
    "    \n",
    "    # Project the latent into parameters of the decoder\n",
    "    pe = proj.apply(params_proj, ov[\"z\"])\n",
    "\n",
    "    # Use in the decoder output to define/update the model parameters\n",
    "    pa = jax.tree.map(lambda x, y: x+y, params_ss, pe)\n",
    "    \n",
    "    y_hat = ss_apply(pa, scalers, ov[\"x0\"], u)\n",
    "    #scaled_err = (y1 - y1_hat) / ckpt[\"sigma_noise\"]\n",
    "    #loss = jnp.sum(scaled_err**2) + jnp.sum(ov[\"z\"]**2)\n",
    "    loss = jnp.mean((y - y_hat)**2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_reduced(ov, y, u, iters=10_000, lr=1e-3):\n",
    "\n",
    "        loss_cfg = partial(loss_reduced, y=y, u=u)\n",
    "        opt = optax.adamw(learning_rate=lr)\n",
    "        state = train_state.TrainState.create(apply_fn=loss_cfg, params=ov, tx=opt)\n",
    "\n",
    "        @jax.jit\n",
    "        def make_step(state):\n",
    "                loss, grads = jax.value_and_grad(state.apply_fn)(state.params)\n",
    "                state = state.apply_gradients(grads=grads)\n",
    "                return loss, state\n",
    "        \n",
    "        losses = jnp.empty(iters)\n",
    "        for idx in (pbar := tqdm(range(iters))):\n",
    "                loss, state = make_step(state)\n",
    "                losses = losses.at[idx].set(loss)\n",
    "                #pbar.set_postfix_str(loss.item())\n",
    "\n",
    "        return state.params, jnp.array(losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_red = onp.empty((len(train_lens), mc_size))\n",
    "train_time = onp.empty(len(train_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mc_size models in parallel!\n",
    "\n",
    "for len_idx, train_len in enumerate(train_lens):\n",
    "\n",
    "    print(f\"Processing length {train_len}...\")\n",
    "    \n",
    "    time_start = time.time()\n",
    "    # generate mc sequences\n",
    "    key, subkey = jr.split(key)     \n",
    "    start_indexes = jr.randint(subkey, shape=(mc_size,),  minval=0, maxval=N-train_len)\n",
    "    mc_indexes = start_indexes[:, None] + jnp.arange(train_len)\n",
    "    mc_y, mc_u = y_train[mc_indexes], u_train[mc_indexes]\n",
    "\n",
    "    print(f\"Training {mc_size} reduced models...\")\n",
    "    # train reduced models\n",
    "    z_init = jnp.zeros((mc_size, cfg.nz, ))\n",
    "    z_init = jax.vmap(enc.apply, in_axes=(None, 0, 0))(params_enc, mc_y, mc_u)\n",
    "    opt_vars_red_init = {\"z\": z_init, \"x0\": jnp.zeros((mc_size, cfg.nx, ))}\n",
    "    opt_vars_red, losses_red = jax.vmap(train_reduced, in_axes=(0, 0, 0))(opt_vars_red_init, mc_y, mc_u)\n",
    "\n",
    "    # project trained zetas to the ss parameter space\n",
    "    params_ss_proj = jax.vmap(proj.apply, in_axes=(None, 0))(params_proj, opt_vars_red[\"z\"])\n",
    "    params_red = jax.tree.map(lambda x, y: x+y, params_ss, params_ss_proj)\n",
    "\n",
    "    train_time[len_idx] = time.time() - time_start\n",
    "    \n",
    "    # test reduced models\n",
    "    x0 = jnp.zeros((cfg.nx, ))\n",
    "    y_test_hat = jax.vmap(ss_apply, in_axes=(0, None, None, None))(params_red, scalers, x0, u_test)\n",
    "\n",
    "    for mc_idx in range(mc_size):\n",
    "        fit_red[len_idx, mc_idx] = nonlinear_benchmarks.error_metrics.fit_index(y_test[cfg.skip_loss:], y_test_hat[mc_idx, cfg.skip_loss:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final checkpoint\n",
    "ckpt = {\n",
    "    \"train_lens\": train_lens,\n",
    "    \"train_time\": train_time,\n",
    "    \"fit\": fit_red,\n",
    "}\n",
    "\n",
    "ckpt_path = Path(\"out\") / f\"mc_red.p\"\n",
    "ckpt_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "pickle.dump(ckpt, open(ckpt_path, \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
