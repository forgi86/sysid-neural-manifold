{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single full-order model on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.flatten_util\n",
    "import optax\n",
    "import jaxopt\n",
    "from flax.training import train_state\n",
    "import scipy\n",
    "from neuralss import ss_init, ss_apply\n",
    "import matplotlib.pyplot as plt\n",
    "import nonlinear_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"nu\": 1,\n",
    "    \"ny\": 1,\n",
    "    \"nx\": 3,\n",
    "    \"hidden_f\": 16,\n",
    "    \"hidden_g\": 16,\n",
    "    \"skip_loss\": 500,\n",
    "}\n",
    "cfg = Namespace(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.key(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "dtype_adam = jnp.float32\n",
    "dtype_bfgs = jnp.float64 # need float64 to squeeze the last bit of performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lib import xla_bridge\n",
    "jax.config.update(\"jax_default_device\", jax.devices(\"cpu\")[0])\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"bwdataset\"\n",
    "data_folder = Path(data_folder)\n",
    "data = scipy.io.loadmat(data_folder / \"bw_matlab.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = data[\"u\"].reshape(-1, 1)\n",
    "y_train = data[\"y\"].reshape(-1, 1)\n",
    "\n",
    "u_train = u_train / 50.0\n",
    "y_train = y_train / 7e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = scipy.io.loadmat(data_folder / \"uval_multisine.mat\")[\"uval_multisine\"].reshape(-1, 1)\n",
    "y_test = scipy.io.loadmat(data_folder / \"yval_multisine.mat\")[\"yval_multisine\"].reshape(-1, 1)\n",
    "\n",
    "u_test = u_test / 50.0\n",
    "y_test = y_test / 7e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\"f\": {\"lin\": 1e-2, \"nl\": 1e-2}, \"g\": {\"lin\": 1e0, \"nl\": 1e0}}\n",
    "key, subkey = jr.split(key, 2)\n",
    "opt_vars_init = {\"params\": ss_init(subkey, nu=cfg.nu, ny=cfg.ny, nx=cfg.nx), \"x0\": jnp.zeros(cfg.nx, )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_full(ov, y, u):\n",
    "       \n",
    "    y_hat = ss_apply(ov[\"params\"], scalers, ov[\"x0\"], u)\n",
    "    #scaled_err = (y1 - y1_hat) / ckpt[\"sigma_noise\"]\n",
    "    #loss = jnp.sum(scaled_err**2) + jnp.sum(ov[\"z\"]**2)\n",
    "    loss = jnp.mean((y - y_hat)**2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_full_model(ov, y, u, iters=100_000, lr=1e-3):\n",
    "\n",
    "        opt = optax.adamw(learning_rate=lr)\n",
    "        loss_fn = partial(loss_full, y=y, u=u)\n",
    "        state = train_state.TrainState.create(apply_fn=loss_fn, params=ov, tx=opt)\n",
    "\n",
    "        @jax.jit\n",
    "        def make_step(state):\n",
    "                loss, grads = jax.value_and_grad(state.apply_fn)(state.params)\n",
    "                state = state.apply_gradients(grads=grads)\n",
    "                return loss, state\n",
    "        \n",
    "        losses = jnp.empty(iters)\n",
    "        for idx in (pbar := tqdm(range(iters))):\n",
    "                loss, state = make_step(state)\n",
    "                losses = losses.at[idx].set(loss)\n",
    "                pbar.set_postfix_str(loss.item())\n",
    "\n",
    "        return state.params, jnp.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_vars_adam, losses_adam = train_full_model(opt_vars_init, y=y_train.astype(dtype_adam), u=u_train.astype(dtype_adam), iters=40_000, lr=1e-3)\n",
    "tima_adam = time.time() - time_start\n",
    "print(f\"Adam took {tima_adam:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"disp\": True, \"return_all\": True} #, 'iprint': 1}\n",
    "\n",
    "loss_bfgs = partial(loss_full, y=y_train.astype(dtype_bfgs), u=u_train.astype(dtype_bfgs))\n",
    "solver = jaxopt.ScipyMinimize(\n",
    "    fun=loss_bfgs, tol=1e-6, method=\"BFGS\", maxiter=10_000, options=options)\n",
    "\n",
    "opt_vars_bfgs, state_full_bfgs = solver.run(opt_vars_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = time.time() - time_start\n",
    "print(f\"Training time: {train_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use in the decoder both to define x0 and the model parameters\n",
    "x0 = jnp.zeros((cfg.nx, ))\n",
    "y2_hat = ss_apply(opt_vars_bfgs[\"params\"], scalers, x0, u_test)\n",
    "#y2_hat = ss_apply(opt_vars_adam[\"params\"], scalers, x0, u2)\n",
    "plt.figure()\n",
    "plt.plot(y_test, \"k\", label=\"true\")\n",
    "plt.plot(y2_hat, \"b\", label=\"reconstructed\")\n",
    "plt.plot(y_test - y2_hat, \"r\", label=\"reconstruction error\")\n",
    "plt.axvline(cfg.skip_loss, color=\"k\")\n",
    "plt.ylim([-4, 4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_full = nonlinear_benchmarks.error_metrics.fit_index(y_test[cfg.skip_loss:], y2_hat[cfg.skip_loss:])\n",
    "rmse_full = nonlinear_benchmarks.error_metrics.RMSE(y_test[cfg.skip_loss:], y2_hat[cfg.skip_loss:])*7e-4 * 1e5\n",
    "fit_full, rmse_full \n",
    "print(f\"Fit index: {fit_full[0]:.2f} %\")\n",
    "print(f\"RMSE: {rmse_full[0]:.2f}e-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use in the decoder both to define x0 and the model parameters\n",
    "y1_hat = ss_apply(opt_vars_bfgs[\"params\"], scalers, opt_vars_bfgs[\"x0\"], u_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_train, \"k\", label=\"true\")\n",
    "plt.plot(y1_hat, \"b\", label=\"reconstructed\")\n",
    "plt.plot(y_train - y1_hat, \"r\", label=\"reconstruction error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = loss_bfgs\n",
    "opt_vars_full_flat, unflatten_full = jax.flatten_util.ravel_pytree(opt_vars_bfgs)\n",
    "loss_fn_flat = lambda of: loss_fn(unflatten_full(of))\n",
    "loss_fn_flat(opt_vars_full_flat)\n",
    "H = jax.hessian(loss_fn_flat)(opt_vars_full_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Path(\"out\") / \"full_alldata.pkl\" \n",
    "\n",
    "ckpt = {\n",
    "    \"H\": H,\n",
    "    \"params\": opt_vars_bfgs[\"params\"],\n",
    "    \"x0\": opt_vars_bfgs[\"x0\"],\n",
    "    \"cfg\": cfg,\n",
    "    \"scalers\": scalers,\n",
    "    \"train_time_adam\": tima_adam,\n",
    "    \"train_time\": train_time,\n",
    "}\n",
    "\n",
    "pickle.dump(ckpt, open(filename, \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time: 5068.36 s\n",
    "# Fit index: 98.91 %\n",
    "# RMSE: 0.73e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
