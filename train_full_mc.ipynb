{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import numpy as onp\n",
    "import jax.flatten_util\n",
    "import pandas as pd\n",
    "import optax\n",
    "import jaxopt\n",
    "from flax.training import train_state\n",
    "import scipy\n",
    "from neuralss import ss_init, ss_apply\n",
    "from ae import Encoder, Projector\n",
    "import nonlinear_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.key(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_default_device\", jax.devices(\"gpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path(\"out\") / f\"vae.p\"\n",
    "ckpt = pickle.load(open(ckpt_path, \"rb\"))\n",
    "\n",
    "cfg = ckpt[\"cfg\"]\n",
    "params_enc = ckpt[\"params_enc\"]\n",
    "params_ss = ckpt[\"params_dec\"] \n",
    "params_proj = ckpt[\"params_proj\"]\n",
    "sigma_noise = ckpt[\"sigma_noise\"]\n",
    "scalers = ckpt[\"scalers\"]\n",
    "params_dec_flat, unflatten_dec = jax.flatten_util.ravel_pytree(params_ss)\n",
    "n_params = params_dec_flat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lens = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1_000, 2000, 3000, 4000, 5000]\n",
    "#train_lens = [100, 200]\n",
    "mc_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"bwdataset\"\n",
    "data_folder = Path(data_folder)\n",
    "data = scipy.io.loadmat(data_folder / \"bw_matlab.mat\")\n",
    "\n",
    "y_train = data[\"y\"] / 7e-4\n",
    "u_train = data[\"u\"] / 50.0\n",
    "\n",
    "y_test = scipy.io.loadmat(data_folder / \"yval_multisine.mat\")[\"yval_multisine\"].reshape(-1, 1) / 7e-4\n",
    "u_test = scipy.io.loadmat(data_folder / \"uval_multisine.mat\")[\"uval_multisine\"].reshape(-1, 1) / 50.0\n",
    "N = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = Projector(outputs=n_params, unflatten=unflatten_dec)\n",
    "enc = Encoder(mlp_layers=[cfg.nh, cfg.nz], rnn_size=cfg.nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_full(ov, y, u):\n",
    "    y_hat = ss_apply(ov[\"params\"], scalers, ov[\"x0\"], u)\n",
    "    #scaled_err = (y1 - y1_hat) / ckpt[\"sigma_noise\"]\n",
    "    #loss = jnp.sum(scaled_err**2) + jnp.sum(ov[\"z\"]**2)\n",
    "    loss = jnp.mean((y - y_hat)**2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_full(ov, y, u, iters=40_000, lr=1e-3):\n",
    "        loss_cfg = partial(loss_full, y=y, u=u)\n",
    "        opt = optax.adamw(learning_rate=lr)\n",
    "        state = train_state.TrainState.create(apply_fn=loss_cfg, params=ov, tx=opt)\n",
    "\n",
    "        @jax.jit\n",
    "        def make_step(state):\n",
    "                loss, grads = jax.value_and_grad(state.apply_fn)(state.params)\n",
    "                state = state.apply_gradients(grads=grads)\n",
    "                return loss, state\n",
    "        \n",
    "        losses = jnp.empty(iters)\n",
    "        for idx in (pbar := tqdm(range(iters))):\n",
    "                loss, state = make_step(state)\n",
    "                losses = losses.at[idx].set(loss)\n",
    "                #pbar.set_postfix_str(loss.item())\n",
    "\n",
    "        return state.params, jnp.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_adam = onp.empty((len(train_lens), mc_size))\n",
    "fit_bfgs = onp.empty((len(train_lens), mc_size))\n",
    "fit_red = onp.empty((len(train_lens), mc_size))\n",
    "train_time_adam = onp.empty(len(train_lens))\n",
    "train_time = onp.empty(len(train_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mc_size models in parallel!\n",
    "\n",
    "for len_idx, train_len in enumerate(train_lens):\n",
    "\n",
    "    print(f\"Processing length {train_len}...\")\n",
    "    \n",
    "    # generate mc sequences\n",
    "    key, subkey = jr.split(key)     \n",
    "    start_indexes = jr.randint(subkey, shape=(mc_size,),  minval=0, maxval=N-train_len)\n",
    "    mc_indexes = start_indexes[:, None] + jnp.arange(train_len)\n",
    "    mc_y, mc_u = y_train[mc_indexes], u_train[mc_indexes]\n",
    "\n",
    "    time_start = time.time()\n",
    "    # train adam models\n",
    "    print(f\"Training  {mc_size} full models with ADAM...\")\n",
    "    key, subkey = jr.split(key)\n",
    "    keys_init = jr.split(subkey, mc_size)\n",
    "    params_init = jax.vmap(ss_init)(keys_init)\n",
    "    opt_vars_init = {\"params\": params_init, \n",
    "                        \"x0\": jnp.zeros((mc_size, cfg.nx))}\n",
    "    opt_vars_adam, losses_full_adam = jax.vmap(train_full, in_axes=(0, 0, 0))(opt_vars_init, mc_y, mc_u)\n",
    "    train_time_adam[len_idx] = time.time() - time_start\n",
    "\n",
    "    # test adam models\n",
    "    x0 = jnp.zeros((cfg.nx, ))\n",
    "    y_test_hat = jax.vmap(ss_apply, in_axes=(0, None, None, None))(opt_vars_adam[\"params\"], scalers, x0, u_test)\n",
    "    for mc_idx in range(mc_size):\n",
    "        fit_adam[len_idx, mc_idx] = nonlinear_benchmarks.error_metrics.fit_index(y_test[cfg.skip_loss:], y_test_hat[mc_idx, cfg.skip_loss:])[0]\n",
    "\n",
    "    # train bfgs models\n",
    "    opt_vars_bfgs = []\n",
    "    states_bfgs = []\n",
    "    for mc_idx in range(mc_size):\n",
    "        print(f\"Training model {mc_idx} with BFGS...\")\n",
    "        loss_i = partial(loss_full, y=mc_y[mc_idx], u=mc_u[mc_idx])\n",
    "        solver = jaxopt.ScipyMinimize(fun=loss_i, tol=1e-6, method=\"BFGS\", maxiter=10_000)\n",
    "        ov_adam_i = jax.tree.map(lambda x: x[mc_idx], opt_vars_adam)\n",
    "        ov_bfgs, s_bfgs = solver.run(ov_adam_i)\n",
    "        opt_vars_bfgs.append(ov_bfgs)\n",
    "        states_bfgs.append(s_bfgs)    \n",
    "    opt_vars_bfgs = jax.tree.map(lambda *x: jnp.stack(x), *opt_vars_bfgs)\n",
    "    states_bfgs = jax.tree.map(lambda *x: jnp.stack(x), *states_bfgs)\n",
    "\n",
    "    train_time[len_idx] = time.time() - time_start\n",
    "\n",
    "    # test bfgs models\n",
    "    x0 = jnp.zeros((cfg.nx, ))\n",
    "    y_test_hat = jax.vmap(ss_apply, in_axes=(0, None, None, None))(opt_vars_bfgs[\"params\"], scalers, x0, u_test)\n",
    "    for mc_idx in range(mc_size):\n",
    "        fit_bfgs[len_idx, mc_idx] = nonlinear_benchmarks.error_metrics.fit_index(y_test[cfg.skip_loss:], y_test_hat[mc_idx, cfg.skip_loss:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adam = pd.DataFrame(fit_adam.T, columns=[str(l) for l in train_lens])\n",
    "df_adam = df_adam.melt(var_name=\"length\", value_name=\"fit\")\n",
    "df_adam.insert(0, \"model\", \"full (adam)\")\n",
    "\n",
    "df_bfgs = pd.DataFrame(fit_bfgs.T, columns=[str(l) for l in train_lens])\n",
    "df_bfgs = df_bfgs.melt(var_name=\"length\", value_name=\"fit\")\n",
    "df_bfgs.insert(0, \"model\", \"full (bfgs)\")\n",
    "\n",
    "df_all = pd.concat((df_adam, df_bfgs), ignore_index=True)\n",
    "df_all.to_pickle(Path(\"out\") / \"df_mc_full.pkl\")\n",
    "\n",
    "df_time = pd.DataFrame({\"length\": train_lens, \"time_adam\": train_time_adam, \"time\": train_time})\n",
    "df_time.to_pickle(Path(\"out\") / \"df_mc_full_time.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
